{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":1032238,"sourceType":"datasetVersion","datasetId":568973}],"dockerImageVersionId":31090,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# ML libs\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.pipeline import Pipeline\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.metrics import accuracy_score, classification_report, confusion_matrix\nimport joblib\n\n# audio / image / torch\nimport librosa, librosa.display\nimport torch, torch.nn as nn, torch.optim as optim\nfrom torch.utils.data import DataLoader\nfrom torchvision import transforms, models, datasets\n\n# plotting & utils\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport numpy as np, pandas as pd, os, io, random\nfrom PIL import Image\nfrom tqdm import tqdm\n\n# Gradio\nimport gradio as gr\n\n# ---------- Paths ----------\nAUDIO_DIR = \"/kaggle/input/gtzan-dataset-music-genre-classification/Data/genres_original\"\nIMG_DIR   = \"/kaggle/input/gtzan-dataset-music-genre-classification/Data/images_original\"\nCSV_FILE  = \"/kaggle/input/gtzan-dataset-music-genre-classification/Data/features_30_sec.csv\"\nWORK_DIR  = \"/kaggle/working\"\nos.makedirs(WORK_DIR, exist_ok=True)\n\nprint(\"Working dir:\", WORK_DIR)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-09T21:40:44.390434Z","iopub.execute_input":"2025-09-09T21:40:44.391027Z","iopub.status.idle":"2025-09-09T21:40:44.400324Z","shell.execute_reply.started":"2025-09-09T21:40:44.390992Z","shell.execute_reply":"2025-09-09T21:40:44.399419Z"}},"outputs":[{"name":"stdout","text":"Working dir: /kaggle/working\n","output_type":"stream"}],"execution_count":13},{"cell_type":"code","source":"SAMPLE_RATE = 22050\nDURATION = 30\nRANDOM_STATE = 42\n\ndef discover_genres_from_audio_dir(audio_dir=AUDIO_DIR):\n    return sorted([d for d in os.listdir(audio_dir) if os.path.isdir(os.path.join(audio_dir, d))]) if os.path.exists(audio_dir) else []\n\ndef list_image_classes(img_dir=IMG_DIR):\n    return sorted([d for d in os.listdir(img_dir) if os.path.isdir(os.path.join(img_dir, d))]) if os.path.exists(img_dir) else []\n\ndef load_audio(path, sr=SAMPLE_RATE, duration=DURATION):\n    y, _ = librosa.load(path, sr=sr, mono=True, duration=duration)\n    if len(y) < sr * duration:\n        y = np.pad(y, (0, max(0, sr * duration - len(y))))\n    return y\n\ndef make_mel_spectrogram_image(y, sr=SAMPLE_RATE, n_mels=128, fmax=8000):\n    S = librosa.feature.melspectrogram(y=y, sr=sr, n_mels=n_mels, fmax=fmax)\n    S_db = librosa.power_to_db(S, ref=np.max)\n    fig = plt.Figure(figsize=(3,3), dpi=100)\n    ax = fig.add_subplot(111); ax.axis('off')\n    librosa.display.specshow(S_db, sr=sr, fmax=fmax, ax=ax)\n    buf = io.BytesIO()\n    fig.savefig(buf, bbox_inches='tight', pad_inches=0)\n    plt.close(fig); buf.seek(0)\n    return Image.open(buf).convert('RGB')\n\ndef extract_features_from_audio(path, sr=SAMPLE_RATE, n_mfcc=20):\n    y = load_audio(path, sr=sr)\n    mfcc = librosa.feature.mfcc(y=y, sr=sr, n_mfcc=n_mfcc)\n    chroma = librosa.feature.chroma_stft(y=y, sr=sr)\n    contrast = librosa.feature.spectral_contrast(y=y, sr=sr)\n    tonnetz = librosa.feat","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-09T21:40:49.114051Z","iopub.execute_input":"2025-09-09T21:40:49.114303Z","iopub.status.idle":"2025-09-09T21:40:49.122896Z","shell.execute_reply.started":"2025-09-09T21:40:49.114283Z","shell.execute_reply":"2025-09-09T21:40:49.122099Z"}},"outputs":[],"execution_count":14},{"cell_type":"code","source":"df = pd.read_csv(CSV_FILE)\nprint(\"CSV shape:\", df.shape)\nprint(\"Columns:\", df.columns[:20])\n\nlabel_col = next((c for c in df.columns if c.lower() in (\"label\",\"genre\")), None)\nfilename_col = next((c for c in df.columns if \"file\" in c.lower()), None)\n\nprint(\"Detected label column:\", label_col)\nprint(df[label_col].value_counts())\ndf.head()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-09T21:40:56.272452Z","iopub.execute_input":"2025-09-09T21:40:56.273320Z","iopub.status.idle":"2025-09-09T21:40:56.320337Z","shell.execute_reply.started":"2025-09-09T21:40:56.273285Z","shell.execute_reply":"2025-09-09T21:40:56.319796Z"}},"outputs":[{"name":"stdout","text":"CSV shape: (1000, 60)\nColumns: Index(['filename', 'length', 'chroma_stft_mean', 'chroma_stft_var', 'rms_mean',\n       'rms_var', 'spectral_centroid_mean', 'spectral_centroid_var',\n       'spectral_bandwidth_mean', 'spectral_bandwidth_var', 'rolloff_mean',\n       'rolloff_var', 'zero_crossing_rate_mean', 'zero_crossing_rate_var',\n       'harmony_mean', 'harmony_var', 'perceptr_mean', 'perceptr_var', 'tempo',\n       'mfcc1_mean'],\n      dtype='object')\nDetected label column: label\nlabel\nblues        100\nclassical    100\ncountry      100\ndisco        100\nhiphop       100\njazz         100\nmetal        100\npop          100\nreggae       100\nrock         100\nName: count, dtype: int64\n","output_type":"stream"},{"execution_count":15,"output_type":"execute_result","data":{"text/plain":"          filename  length  chroma_stft_mean  chroma_stft_var  rms_mean  \\\n0  blues.00000.wav  661794          0.350088         0.088757  0.130228   \n1  blues.00001.wav  661794          0.340914         0.094980  0.095948   \n2  blues.00002.wav  661794          0.363637         0.085275  0.175570   \n3  blues.00003.wav  661794          0.404785         0.093999  0.141093   \n4  blues.00004.wav  661794          0.308526         0.087841  0.091529   \n\n    rms_var  spectral_centroid_mean  spectral_centroid_var  \\\n0  0.002827             1784.165850          129774.064525   \n1  0.002373             1530.176679          375850.073649   \n2  0.002746             1552.811865          156467.643368   \n3  0.006346             1070.106615          184355.942417   \n4  0.002303             1835.004266          343399.939274   \n\n   spectral_bandwidth_mean  spectral_bandwidth_var  ...  mfcc16_var  \\\n0              2002.449060            85882.761315  ...   52.420910   \n1              2039.036516           213843.755497  ...   55.356403   \n2              1747.702312            76254.192257  ...   40.598766   \n3              1596.412872           166441.494769  ...   44.427753   \n4              1748.172116            88445.209036  ...   86.099236   \n\n   mfcc17_mean  mfcc17_var  mfcc18_mean  mfcc18_var  mfcc19_mean  mfcc19_var  \\\n0    -1.690215   36.524071    -0.408979   41.597103    -2.303523   55.062923   \n1    -0.731125   60.314529     0.295073   48.120598    -0.283518   51.106190   \n2    -7.729093   47.639427    -1.816407   52.382141    -3.439720   46.639660   \n3    -3.319597   50.206673     0.636965   37.319130    -0.619121   37.259739   \n4    -5.454034   75.269707    -0.916874   53.613918    -4.404827   62.910812   \n\n   mfcc20_mean  mfcc20_var  label  \n0     1.221291   46.936035  blues  \n1     0.531217   45.786282  blues  \n2    -2.231258   30.573025  blues  \n3    -3.407448   31.949339  blues  \n4   -11.703234   55.195160  blues  \n\n[5 rows x 60 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>filename</th>\n      <th>length</th>\n      <th>chroma_stft_mean</th>\n      <th>chroma_stft_var</th>\n      <th>rms_mean</th>\n      <th>rms_var</th>\n      <th>spectral_centroid_mean</th>\n      <th>spectral_centroid_var</th>\n      <th>spectral_bandwidth_mean</th>\n      <th>spectral_bandwidth_var</th>\n      <th>...</th>\n      <th>mfcc16_var</th>\n      <th>mfcc17_mean</th>\n      <th>mfcc17_var</th>\n      <th>mfcc18_mean</th>\n      <th>mfcc18_var</th>\n      <th>mfcc19_mean</th>\n      <th>mfcc19_var</th>\n      <th>mfcc20_mean</th>\n      <th>mfcc20_var</th>\n      <th>label</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>blues.00000.wav</td>\n      <td>661794</td>\n      <td>0.350088</td>\n      <td>0.088757</td>\n      <td>0.130228</td>\n      <td>0.002827</td>\n      <td>1784.165850</td>\n      <td>129774.064525</td>\n      <td>2002.449060</td>\n      <td>85882.761315</td>\n      <td>...</td>\n      <td>52.420910</td>\n      <td>-1.690215</td>\n      <td>36.524071</td>\n      <td>-0.408979</td>\n      <td>41.597103</td>\n      <td>-2.303523</td>\n      <td>55.062923</td>\n      <td>1.221291</td>\n      <td>46.936035</td>\n      <td>blues</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>blues.00001.wav</td>\n      <td>661794</td>\n      <td>0.340914</td>\n      <td>0.094980</td>\n      <td>0.095948</td>\n      <td>0.002373</td>\n      <td>1530.176679</td>\n      <td>375850.073649</td>\n      <td>2039.036516</td>\n      <td>213843.755497</td>\n      <td>...</td>\n      <td>55.356403</td>\n      <td>-0.731125</td>\n      <td>60.314529</td>\n      <td>0.295073</td>\n      <td>48.120598</td>\n      <td>-0.283518</td>\n      <td>51.106190</td>\n      <td>0.531217</td>\n      <td>45.786282</td>\n      <td>blues</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>blues.00002.wav</td>\n      <td>661794</td>\n      <td>0.363637</td>\n      <td>0.085275</td>\n      <td>0.175570</td>\n      <td>0.002746</td>\n      <td>1552.811865</td>\n      <td>156467.643368</td>\n      <td>1747.702312</td>\n      <td>76254.192257</td>\n      <td>...</td>\n      <td>40.598766</td>\n      <td>-7.729093</td>\n      <td>47.639427</td>\n      <td>-1.816407</td>\n      <td>52.382141</td>\n      <td>-3.439720</td>\n      <td>46.639660</td>\n      <td>-2.231258</td>\n      <td>30.573025</td>\n      <td>blues</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>blues.00003.wav</td>\n      <td>661794</td>\n      <td>0.404785</td>\n      <td>0.093999</td>\n      <td>0.141093</td>\n      <td>0.006346</td>\n      <td>1070.106615</td>\n      <td>184355.942417</td>\n      <td>1596.412872</td>\n      <td>166441.494769</td>\n      <td>...</td>\n      <td>44.427753</td>\n      <td>-3.319597</td>\n      <td>50.206673</td>\n      <td>0.636965</td>\n      <td>37.319130</td>\n      <td>-0.619121</td>\n      <td>37.259739</td>\n      <td>-3.407448</td>\n      <td>31.949339</td>\n      <td>blues</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>blues.00004.wav</td>\n      <td>661794</td>\n      <td>0.308526</td>\n      <td>0.087841</td>\n      <td>0.091529</td>\n      <td>0.002303</td>\n      <td>1835.004266</td>\n      <td>343399.939274</td>\n      <td>1748.172116</td>\n      <td>88445.209036</td>\n      <td>...</td>\n      <td>86.099236</td>\n      <td>-5.454034</td>\n      <td>75.269707</td>\n      <td>-0.916874</td>\n      <td>53.613918</td>\n      <td>-4.404827</td>\n      <td>62.910812</td>\n      <td>-11.703234</td>\n      <td>55.195160</td>\n      <td>blues</td>\n    </tr>\n  </tbody>\n</table>\n<p>5 rows × 60 columns</p>\n</div>"},"metadata":{}}],"execution_count":15},{"cell_type":"code","source":"SUBSET_PER_CLASS = 100\n\nX_df = df.drop(columns=[c for c in (label_col, filename_col) if c in df.columns])\nX, y = X_df.values, df[label_col].values\n\n# Subsample\ntmp = pd.DataFrame(X); tmp[label_col] = y\nsampled = tmp.groupby(label_col).apply(lambda g: g.sample(min(len(g), SUBSET_PER_CLASS), random_state=RANDOM_STATE)).reset_index(drop=True)\ny = sampled[label_col].values\nX = sampled.drop(columns=[label_col]).values\n\nX_train, X_test, y_train, y_test = train_test_split(X, y, stratify=y, test_size=0.2, random_state=RANDOM_STATE)\nclf = Pipeline([(\"scaler\", StandardScaler()), (\"rf\", RandomForestClassifier(n_estimators=200, random_state=RANDOM_STATE, n_jobs=-1))])\nclf.fit(X_train, y_train)\n\npreds = clf.predict(X_test)\nprint(\"Tabular accuracy:\", accuracy_score(y_test, preds))\nprint(classification_report(y_test, preds))\njoblib.dump(clf, os.path.join(WORK_DIR, \"tabular_rf.joblib\"))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-09T21:41:00.310352Z","iopub.execute_input":"2025-09-09T21:41:00.310927Z","iopub.status.idle":"2025-09-09T21:41:01.081894Z","shell.execute_reply.started":"2025-09-09T21:41:00.310904Z","shell.execute_reply":"2025-09-09T21:41:01.081283Z"}},"outputs":[{"name":"stdout","text":"Tabular accuracy: 0.795\n              precision    recall  f1-score   support\n\n       blues       0.65      0.65      0.65        20\n   classical       0.86      0.90      0.88        20\n     country       0.62      0.65      0.63        20\n       disco       0.88      0.75      0.81        20\n      hiphop       0.89      0.80      0.84        20\n        jazz       0.80      0.80      0.80        20\n       metal       0.90      0.95      0.93        20\n         pop       0.95      1.00      0.98        20\n      reggae       0.72      0.90      0.80        20\n        rock       0.69      0.55      0.61        20\n\n    accuracy                           0.80       200\n   macro avg       0.80      0.80      0.79       200\nweighted avg       0.80      0.80      0.79       200\n\n","output_type":"stream"},{"execution_count":16,"output_type":"execute_result","data":{"text/plain":"['/kaggle/working/tabular_rf.joblib']"},"metadata":{}}],"execution_count":16},{"cell_type":"code","source":"device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n\ndata_transforms = {\n    \"train\": transforms.Compose([transforms.Resize((224,224)), transforms.RandomHorizontalFlip(), transforms.ToTensor(),\n                                 transforms.Normalize([0.485,0.456,0.406],[0.229,0.224,0.225])]),\n    \"val\": transforms.Compose([transforms.Resize((224,224)), transforms.ToTensor(),\n                               transforms.Normalize([0.485,0.456,0.406],[0.229,0.224,0.225])])\n}\n\nfull_ds = datasets.ImageFolder(IMG_DIR, transform=data_transforms[\"train\"])\nprint(\"Classes:\", full_ds.classes)\n\nn = len(full_ds)\ntrain_size = int(0.8 * n)\nval_size = n - train_size\ntrain_ds, val_ds = torch.utils.data.random_split(full_ds, [train_size, val_size])\nval_ds.dataset.transform = data_transforms[\"val\"]\n\ntrain_loader = DataLoader(train_ds, batch_size=16, shuffle=True, num_workers=2)\nval_loader   = DataLoader(val_ds, batch_size=16, shuffle=False, num_workers=2)\n\n# Model\nmodel = models.resnet18(weights=models.ResNet18_Weights.IMAGENET1K_V1)\nmodel.fc = nn.Linear(model.fc.in_features, len(full_ds.classes))\nmodel = model.to(device)\n\ncriterion = nn.CrossEntropyLoss()\noptimizer = optim.Adam(model.parameters(), lr=1e-4)\n\nEPOCHS = 3\nfor epoch in range(EPOCHS):\n    model.train()\n    for Xb, yb in train_loader:\n        Xb, yb = Xb.to(device), yb.to(device)\n        optimizer.zero_grad()\n        out = model(Xb)\n        loss = criterion(out, yb)\n        loss.backward(); optimizer.step()\n    # Validation\n    correct, total = 0, 0\n    model.eval()\n    with torch.no_grad():\n        for Xb, yb in val_loader:\n            Xb, yb = Xb.to(device), yb.to(device)\n            out = model(Xb)\n            _, pred = torch.max(out, 1)\n            correct += (pred == yb).sum().item()\n            total += yb.size(0)\n    print(f\"Epoch {epoch+1}: Val Acc = {correct/total:.4f}\")\n\ntorch.save({\"model\": model.state_dict(), \"classes\": full_ds.classes}, os.path.join(WORK_DIR, \"transfer_resnet18.pth\"))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-09T21:41:06.086204Z","iopub.execute_input":"2025-09-09T21:41:06.086444Z","iopub.status.idle":"2025-09-09T21:41:20.579931Z","shell.execute_reply.started":"2025-09-09T21:41:06.086430Z","shell.execute_reply":"2025-09-09T21:41:20.578946Z"}},"outputs":[{"name":"stdout","text":"Classes: ['blues', 'classical', 'country', 'disco', 'hiphop', 'jazz', 'metal', 'pop', 'reggae', 'rock']\nEpoch 1: Val Acc = 0.6950\nEpoch 2: Val Acc = 0.6900\nEpoch 3: Val Acc = 0.7200\n","output_type":"stream"}],"execution_count":17},{"cell_type":"code","source":"def predict_tabular_from_audio(audio_path):\n    clf = joblib.load(os.path.join(WORK_DIR, \"tabular_rf.joblib\"))\n    feats = extract_features_from_audio(audio_path).reshape(1,-1)\n    probs = clf.predict_proba(feats)[0]\n    return clf.classes_[np.argmax(probs)], dict(zip(clf.classes_, probs))\n\ndef predict_transfer_from_audio(audio_path):\n    ckpt = torch.load(os.path.join(WORK_DIR, \"transfer_resnet18.pth\"), map_location=\"cpu\")\n    classes = ckpt[\"classes\"]\n    model = models.resnet18(weights=None)\n    model.fc = nn.Linear(model.fc.in_features, len(classes))\n    model.load_state_dict(ckpt[\"model\"]); model.eval()\n\n    y = load_audio(audio_path)\n    img = make_mel_spectrogram_image(y)\n    transform = transforms.Compose([transforms.Resize((224,224)), transforms.ToTensor(),\n                                    transforms.Normalize([0.485,0.456,0.406],[0.229,0.224,0.225])])\n    X = transform(img).unsqueeze(0)\n    with torch.no_grad():\n        out = model(X); probs = torch.softmax(out, 1)[0].numpy()\n    return classes[int(np.argmax(probs))], dict(zip(classes, probs))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-09T21:41:30.001087Z","iopub.execute_input":"2025-09-09T21:41:30.001846Z","iopub.status.idle":"2025-09-09T21:41:30.008625Z","shell.execute_reply.started":"2025-09-09T21:41:30.001816Z","shell.execute_reply":"2025-09-09T21:41:30.007930Z"}},"outputs":[],"execution_count":18},{"cell_type":"code","source":"def gr_wrapper(audio, model_choice):\n    if model_choice == \"Tabular\":\n        return predict_tabular_from_audio(audio)\n    else:\n        return predict_transfer_from_audio(audio)\n\niface = gr.Interface(\n    fn=gr_wrapper,\n    inputs=[gr.Audio(type=\"filepath\"), gr.Radio([\"Tabular\",\"Transfer\"], value=\"Transfer\")],\n    outputs=[gr.Textbox(label=\"Predicted Genre\"), gr.Label(label=\"Probabilities\")],\n    title=\"GTZAN Music Genre Classifier 🎶\"\n)\n\niface.launch(share=True)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-09T21:43:38.555619Z","iopub.execute_input":"2025-09-09T21:43:38.556179Z","iopub.status.idle":"2025-09-09T21:43:39.514863Z","shell.execute_reply.started":"2025-09-09T21:43:38.556158Z","shell.execute_reply":"2025-09-09T21:43:39.514194Z"}},"outputs":[{"name":"stdout","text":"* Running on local URL:  http://127.0.0.1:7862\n* Running on public URL: https://892a02f9d3b66f0ae0.gradio.live\n\nThis share link expires in 1 week. For free permanent hosting and GPU upgrades, run `gradio deploy` from the terminal in the working directory to deploy to Hugging Face Spaces (https://huggingface.co/spaces)\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"<div><iframe src=\"https://892a02f9d3b66f0ae0.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"},"metadata":{}},{"execution_count":20,"output_type":"execute_result","data":{"text/plain":""},"metadata":{}}],"execution_count":20}]}